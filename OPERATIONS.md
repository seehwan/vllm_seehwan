# ğŸš€ vLLM ì±—ë´‡ ì„œë¹„ìŠ¤ ìš´ì˜ ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” vLLM ê¸°ë°˜ ì±—ë´‡ ì„œë¹„ìŠ¤ì˜ ì¼ìƒì ì¸ ìš´ì˜, ëª¨ë‹ˆí„°ë§, ìœ ì§€ë³´ìˆ˜ë¥¼ ìœ„í•œ ì‹¤ë¬´ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“Š ì¼ì¼ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ğŸŒ… ì•„ì¹¨ ì²´í¬ (ìš´ì˜ ì‹œì‘)

```bash
# 1. ì „ì²´ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker compose ps

# 2. í—¬ìŠ¤ì²´í¬ ìˆ˜í–‰
curl -f http://localhost:8080/health
curl -f http://localhost:8000/v1/models

# 3. GPU ìƒíƒœ í™•ì¸
nvidia-smi

# 4. ë””ìŠ¤í¬ ìš©ëŸ‰ í™•ì¸
df -h

# 5. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
free -h

# 6. ì§€ë‚œ ë°¤ ì—ëŸ¬ ë¡œê·¸ í™•ì¸
docker compose logs --since 24h | grep -i error
```

### ğŸŒ™ ì €ë… ì²´í¬ (ìš´ì˜ ì¢…ë£Œ ì „)

```bash
# 1. ì˜¤ëŠ˜ í•˜ë£¨ ì‚¬ìš©ëŸ‰ í†µê³„
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "
SELECT
    COUNT(*) as total_requests,
    AVG(latency_ms) as avg_latency,
    COUNT(CASE WHEN status_code >= 400 THEN 1 END) as errors
FROM request_logs
WHERE created_at >= CURRENT_DATE;"

# 2. ë¡œê·¸ ë¡œí…Œì´ì…˜
docker compose logs --no-color > "logs/app_$(date +%Y%m%d).log"

# 3. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
./scripts/backup_database.sh

# 4. GPU ì˜¨ë„ ë° ì‚¬ìš©ë¥  ìµœì¢… í™•ì¸
nvidia-smi
```

## ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### í•µì‹¬ ì§€í‘œ ëª¨ë‹ˆí„°ë§

#### 1. ì„±ëŠ¥ ì§€í‘œ

```bash
# ì‘ë‹µ ì‹œê°„ ëª¨ë‹ˆí„°ë§
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "
SELECT
    model,
    percentile_cont(0.5) WITHIN GROUP (ORDER BY latency_ms) as p50_latency,
    percentile_cont(0.95) WITHIN GROUP (ORDER BY latency_ms) as p95_latency,
    AVG(latency_ms) as avg_latency
FROM request_logs
WHERE created_at >= NOW() - INTERVAL '1 hour'
GROUP BY model;"
```

#### 2. ì—ëŸ¬ìœ¨ ëª¨ë‹ˆí„°ë§

```bash
# ì‹œê°„ëŒ€ë³„ ì—ëŸ¬ìœ¨ í™•ì¸
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "
SELECT
    DATE_TRUNC('hour', created_at) as hour,
    COUNT(*) as total_requests,
    COUNT(CASE WHEN status_code >= 400 THEN 1 END) as errors,
    ROUND(COUNT(CASE WHEN status_code >= 400 THEN 1 END) * 100.0 / COUNT(*), 2) as error_rate
FROM request_logs
WHERE created_at >= NOW() - INTERVAL '24 hours'
GROUP BY DATE_TRUNC('hour', created_at)
ORDER BY hour DESC;"
```

#### 3. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 

```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì¶”ì 
#!/bin/bash
# monitor_gpu.sh
while true; do
    echo "$(date): $(nvidia-smi --query-gpu=memory.used,memory.total,utilization.gpu --format=csv,noheader,nounits)"
    sleep 300  # 5ë¶„ë§ˆë‹¤ ì²´í¬
done >> gpu_usage.log &
```

### ì•Œë¦¼ ì„¤ì •

#### Slack/Discord ì›¹í›… ì•Œë¦¼

```bash
# webhook_alert.sh
#!/bin/bash

WEBHOOK_URL="https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
ALERT_LEVEL=$1
MESSAGE=$2

curl -X POST -H 'Content-type: application/json' \
    --data "{'text':'[$ALERT_LEVEL] vLLM Service Alert: $MESSAGE'}" \
    $WEBHOOK_URL
```

#### ìë™ ì•Œë¦¼ ì¡°ê±´

```bash
# auto_monitor.sh
#!/bin/bash

# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  90% ì´ìƒ
GPU_USAGE=$(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits | awk -F, '{print int($1/$2*100)}')
if [ $GPU_USAGE -gt 90 ]; then
    ./webhook_alert.sh "WARNING" "GPU memory usage: ${GPU_USAGE}%"
fi

# ì—ëŸ¬ìœ¨ 5% ì´ìƒ
ERROR_RATE=$(docker compose logs --since 1h gateway | grep "ERROR" | wc -l)
if [ $ERROR_RATE -gt 50 ]; then  # 1ì‹œê°„ì— 50ê°œ ì´ìƒ ì—ëŸ¬
    ./webhook_alert.sh "CRITICAL" "High error rate detected: $ERROR_RATE errors in last hour"
fi

# ë””ìŠ¤í¬ ì‚¬ìš©ë¥  85% ì´ìƒ
DISK_USAGE=$(df -h / | awk 'NR==2{print int($5)}')
if [ $DISK_USAGE -gt 85 ]; then
    ./webhook_alert.sh "WARNING" "Disk usage: ${DISK_USAGE}%"
fi
```

## ğŸ”§ ìœ ì§€ë³´ìˆ˜ ì‘ì—…

### ğŸ¯ ëª¨ë¸ ê´€ë¦¬ ìš´ì˜ ê°€ì´ë“œ â­

#### **ì¼ìƒì ì¸ ëª¨ë¸ ìƒíƒœ ëª¨ë‹ˆí„°ë§**
```bash
#!/bin/bash
# model_health_check.sh

echo "ğŸ¤– ëª¨ë¸ ìƒíƒœ ì ê²€: $(date)"

# 1. í˜„ì¬ ëª¨ë¸ ìƒíƒœ í™•ì¸
echo "ğŸ“Š í˜„ì¬ ëª¨ë¸ ìƒíƒœ:"
curl -s http://localhost:8080/api/models/status | jq '{
  current_profile: .current_profile,
  status: .status,
  gpu_memory_used: .hardware_info.gpus[0].memory_used_mb,
  gpu_memory_total: .hardware_info.gpus[0].memory_total_mb
}'

# 2. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  í™•ì¸
GPU_USAGE=$(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits | awk -F, '{print int($1/$2*100)}')
echo "ğŸ–¥ï¸ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : ${GPU_USAGE}%"

# 3. ëª¨ë¸ ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
RESPONSE_TIME=$(curl -w "%{time_total}" -s -o /dev/null -X POST http://localhost:8080/api/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer test-token" \
  -d '{"messages":[{"role":"user","content":"Hi"}],"model":"current","stream":false}')

echo "âš¡ ëª¨ë¸ ì‘ë‹µ ì‹œê°„: ${RESPONSE_TIME}ì´ˆ"

# 4. ê²½ê³  ì„ê³„ê°’ ì²´í¬
if (( $(echo "$RESPONSE_TIME > 5.0" | bc -l) )); then
    echo "âš ï¸ ê²½ê³ : ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤ (${RESPONSE_TIME}ì´ˆ > 5ì´ˆ)"
    ./webhook_alert.sh "WARNING" "Model response time slow: ${RESPONSE_TIME}s"
fi

if [ $GPU_USAGE -gt 95 ]; then
    echo "ğŸ”¥ ìœ„í—˜: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (${GPU_USAGE}%)"
    ./webhook_alert.sh "CRITICAL" "GPU memory critical: ${GPU_USAGE}%"
fi
```

#### **ëª¨ë¸ ì „í™˜ ìš´ì˜ ì ˆì°¨**
```bash
#!/bin/bash  
# model_switch_procedure.sh

MODEL_ID=$1
if [ -z "$MODEL_ID" ]; then
    echo "ì‚¬ìš©ë²•: $0 <profile_id>"
    echo "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: deepseek-r1-distill-qwen-14b, deepseek-coder-7b, qwen2-7b-instruct"
    exit 1
fi

echo "ğŸ”„ ëª¨ë¸ ì „í™˜ ì‹œì‘: $MODEL_ID"

# 1. í˜„ì¬ ìƒíƒœ ë°±ì—…
CURRENT_STATE=$(curl -s http://localhost:8080/api/models/status)
echo "$CURRENT_STATE" > "/tmp/model_state_backup_$(date +%Y%m%d_%H%M%S).json"

# 2. í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± ì‚¬ì „ ê²€ì¦
echo "ğŸ” í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± ê²€ì¦ ì¤‘..."
COMPATIBILITY=$(curl -s http://localhost:8080/api/models/hardware-recommendations | jq --arg model "$MODEL_ID" '.compatible_profiles[] | select(.profile_id == $model)')

if [ -z "$COMPATIBILITY" ]; then
    echo "âŒ ì˜¤ë¥˜: $MODEL_IDëŠ” í˜„ì¬ í•˜ë“œì›¨ì–´ì™€ í˜¸í™˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤"
    exit 1
fi

# 3. ì‚¬ìš©ì í™•ì¸
echo "âœ… í˜¸í™˜ì„± í™•ì¸ ì™„ë£Œ"
echo "í˜„ì¬ í™œì„± ì‚¬ìš©ì ìˆ˜ í™•ì¸ ì¤‘..."
ACTIVE_USERS=$(docker compose exec postgres psql -U $POSTGRES_USER -d $POSTGRES_DB -t -c "SELECT COUNT(DISTINCT user_id) FROM conversations WHERE updated_at > NOW() - INTERVAL '5 minutes';" | xargs)
echo "ğŸ“Š í™œì„± ì‚¬ìš©ì: $ACTIVE_USERSëª…"

if [ "$ACTIVE_USERS" -gt 0 ]; then
    echo "âš ï¸ ì£¼ì˜: í˜„ì¬ $ACTIVE_USERSëª…ì´ ì„œë¹„ìŠ¤ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤"
    echo "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N)"
    read -r CONFIRM
    if [[ ! "$CONFIRM" =~ ^[Yy]$ ]]; then
        echo "ëª¨ë¸ ì „í™˜ ì·¨ì†Œë¨"
        exit 0
    fi
fi

# 4. ëª¨ë¸ ì „í™˜ ì‹¤í–‰
echo "ğŸš€ ëª¨ë¸ ì „í™˜ ìš”ì²­ ì „ì†¡..."
SWITCH_RESULT=$(curl -s -X POST http://localhost:8080/api/models/switch \
    -H "Content-Type: application/json" \
    -d "{\"profile_id\": \"$MODEL_ID\"}")

echo "ğŸ“ ì „í™˜ ì‘ë‹µ: $SWITCH_RESULT"

# 5. ì „í™˜ ì™„ë£Œ ëŒ€ê¸°
echo "â³ ëª¨ë¸ ë¡œë”© ëŒ€ê¸° ì¤‘... (ìµœëŒ€ 5ë¶„)"
for i in {1..60}; do
    STATUS=$(curl -s http://localhost:8080/api/models/status | jq -r '.status')
    if [ "$STATUS" = "running" ]; then
        echo "âœ… ëª¨ë¸ ì „í™˜ ì™„ë£Œ! (${i}0ì´ˆ ì†Œìš”)"
        break
    elif [ "$STATUS" = "error" ]; then
        echo "âŒ ëª¨ë¸ ì „í™˜ ì‹¤íŒ¨!"
        exit 1
    fi
    sleep 5
    echo -n "."
done

# 6. ì „í™˜ ì™„ë£Œ ê²€ì¦
echo ""
echo "ğŸ§ª ëª¨ë¸ ì „í™˜ ê²€ì¦ ì¤‘..."
TEST_RESULT=$(curl -s -X POST http://localhost:8080/api/chat \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer test-token" \
    -d '{"messages":[{"role":"user","content":"ì•ˆë…•í•˜ì„¸ìš”"}],"model":"current","stream":false}')

if echo "$TEST_RESULT" | jq -e '.choices[0].message.content' > /dev/null; then
    echo "âœ… ëª¨ë¸ ì „í™˜ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
    ./webhook_alert.sh "INFO" "Model switched successfully to: $MODEL_ID"
else
    echo "âŒ ëª¨ë¸ ì „í™˜ì€ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨"
    ./webhook_alert.sh "WARNING" "Model switch completed but test failed: $MODEL_ID"
fi
```

#### **ëª¨ë¸ ê´€ë ¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…**

**ğŸ”¥ ì¼ë°˜ì ì¸ ë¬¸ì œì™€ í•´ê²°ì±…:**

1. **ëª¨ë¸ ì „í™˜ì´ ë©ˆì¶¤ (5ë¶„ ì´ìƒ)**
```bash
# í˜„ì¬ vLLM í”„ë¡œì„¸ìŠ¤ í™•ì¸
docker compose exec vllm ps aux | grep python

# GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸  
nvidia-smi

# ê°•ì œ ì¬ì‹œì‘ (ìµœí›„ ìˆ˜ë‹¨)
docker compose restart vllm
sleep 30
curl http://localhost:8080/api/models/reload  # í”„ë¡œíŒŒì¼ ì¬ë¡œë“œ
```

2. **GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (CUDA OOM)**
```bash
# í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
nvidia-smi

# ë” ì‘ì€ ëª¨ë¸ë¡œ ì „í™˜
curl -X POST http://localhost:8080/api/models/switch \
    -H "Content-Type: application/json" \
    -d '{"profile_id": "phi3-mini"}'

# VRAM ì‚¬ìš©ë¥  ì¡°ì • (model_profiles.yml)
# gpu_memory_utilization: 0.85 â†’ 0.7
```

3. **ëª¨ë¸ ì‘ë‹µ í’ˆì§ˆ ì €í•˜**
```bash
# í˜„ì¬ ëª¨ë¸ í™•ì¸
curl http://localhost:8080/api/models/status | jq '.current_profile'

# ëª¨ë¸ë³„ ê¶Œì¥ ë§¤ê°œë³€ìˆ˜ í™•ì¸
curl http://localhost:8080/api/models/profiles | jq '.profiles["current"]["description"]'

# ë” ì í•©í•œ ëª¨ë¸ë¡œ ì „í™˜
curl http://localhost:8080/api/models/hardware-recommendations | jq '.recommended_profiles'
```

4. **ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨**
```bash
# vLLM ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker compose logs vllm | tail -50

# í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ ì¬í™•ì¸
curl http://localhost:8080/api/models/hardware-recommendations

# model_profiles.yml ë¬¸ë²• ê²€ì¦
python3 -c "import yaml; yaml.safe_load(open('model_profiles.yml'))"
```

### ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ (ë§¤ì£¼ ì¼ìš”ì¼)

```bash
#!/bin/bash
# weekly_maintenance.sh

echo "ğŸ”§ ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì‹œì‘: $(date)"

# 1. ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt upgrade -y

# 2. Docker ì •ë¦¬
docker system prune -f
docker volume prune -f

# 3. ë¡œê·¸ íŒŒì¼ ì •ë¦¬ (30ì¼ ì´ìƒëœ íŒŒì¼ ì‚­ì œ)
find logs/ -name "*.log" -mtime +30 -delete

# 4. ë°ì´í„°ë² ì´ìŠ¤ ì§„ê³µì²­ì†Œ
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "VACUUM ANALYZE;"

# 5. GPU ë“œë¼ì´ë²„ ìƒíƒœ í™•ì¸
nvidia-smi -q -d TEMPERATURE,POWER,CLOCK

# 6. ë°±ì—… ë¬´ê²°ì„± ê²€ì¦
./scripts/verify_backups.sh

# 7. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ (ë¶€í•˜ê°€ ì ì€ ì‹œê°„ëŒ€)
./scripts/benchmark.sh

echo "âœ… ì£¼ê°„ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ: $(date)"
```

### ì›”ê°„ ìœ ì§€ë³´ìˆ˜ (ë§¤ì›” ì²«ì§¸ ì£¼)

```bash
#!/bin/bash
# monthly_maintenance.sh

echo "ğŸ”§ ì›”ê°„ ìœ ì§€ë³´ìˆ˜ ì‹œì‘: $(date)"

# 1. ë³´ì•ˆ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt full-upgrade -y

# 2. SSL ì¸ì¦ì„œ ê°±ì‹  í™•ì¸
sudo certbot renew --dry-run

# 3. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì•„ì¹´ì´ë¹™
tar -czf "backups/monthly_backup_$(date +%Y%m).tar.gz" backups/daily/

# 4. ë¡œê·¸ ì•„ì¹´ì´ë¹™
tar -czf "logs/monthly_logs_$(date +%Y%m).tar.gz" logs/daily/

# 5. ì˜ì¡´ì„± ì—…ë°ì´íŠ¸ ê²€í† 
docker compose pull  # ìƒˆ ì´ë¯¸ì§€ í™•ì¸

# 6. ë³´ì•ˆ ìŠ¤ìº”
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
    aquasec/trivy image $(docker compose config --services)

echo "âœ… ì›”ê°„ ìœ ì§€ë³´ìˆ˜ ì™„ë£Œ: $(date)"
```

## ğŸ’¾ ë°±ì—… ë° ë³µêµ¬

### ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/backup_database.sh

BACKUP_DIR="/backups/postgresql"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/chatdb_backup_$DATE.sql"

# ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p $BACKUP_DIR

# ë°ì´í„°ë² ì´ìŠ¤ ë¤í”„
docker compose exec -T postgres pg_dump \
    -U ${POSTGRES_USER} \
    -d ${POSTGRES_DB} \
    --clean --if-exists \
    > $BACKUP_FILE

# ì••ì¶•
gzip $BACKUP_FILE

# 30ì¼ ì´ìƒëœ ë°±ì—… íŒŒì¼ ì‚­ì œ
find $BACKUP_DIR -name "*.gz" -mtime +30 -delete

echo "âœ… ë°±ì—… ì™„ë£Œ: ${BACKUP_FILE}.gz"

# Slack ì•Œë¦¼ (ì„ íƒì‚¬í•­)
# ./webhook_alert.sh "INFO" "Database backup completed: ${BACKUP_FILE}.gz"
```

### ë°±ì—… ë³µêµ¬ ì ˆì°¨

```bash
#!/bin/bash
# scripts/restore_database.sh

BACKUP_FILE=$1

if [ -z "$BACKUP_FILE" ]; then
    echo "ì‚¬ìš©ë²•: ./restore_database.sh backup_file.sql.gz"
    exit 1
fi

echo "âš ï¸  ì£¼ì˜: í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì™„ì „íˆ êµì²´ë©ë‹ˆë‹¤!"
read -p "ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): " -n 1 -r
echo

if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "ë³µêµ¬ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
    exit 1
fi

# ì„œë¹„ìŠ¤ ì¤‘ì§€
docker compose stop gateway frontend

# ë°±ì—… íŒŒì¼ ì••ì¶• í•´ì œ ë° ë³µêµ¬
gunzip -c $BACKUP_FILE | docker compose exec -T postgres psql \
    -U ${POSTGRES_USER} \
    -d ${POSTGRES_DB}

# ì„œë¹„ìŠ¤ ì¬ì‹œì‘
docker compose start gateway frontend

echo "âœ… ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì™„ë£Œ"
```

### ì„¤ì • íŒŒì¼ ë°±ì—…

```bash
#!/bin/bash
# scripts/backup_configs.sh

BACKUP_DIR="/backups/configs"
DATE=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

# ì¤‘ìš” ì„¤ì • íŒŒì¼ë“¤ ë°±ì—…
tar -czf "$BACKUP_DIR/configs_backup_$DATE.tar.gz" \
    .env.local \
    docker-compose.yml \
    nginx/nginx.conf \
    gateway/app/config.py \
    scripts/

echo "âœ… ì„¤ì • íŒŒì¼ ë°±ì—… ì™„ë£Œ: configs_backup_$DATE.tar.gz"
```

## ğŸš¨ ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼

### ì¼ë°˜ì ì¸ ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤

#### 1. vLLM ì„œë¹„ìŠ¤ ë‹¤ìš´

**ì¦ìƒ:**

- 502 Bad Gateway ì˜¤ë¥˜
- `/v1/models` ì—”ë“œí¬ì¸íŠ¸ ì‘ë‹µ ì—†ìŒ

**ëŒ€ì‘ ì ˆì°¨:**

```bash
# 1. ë¡œê·¸ í™•ì¸
docker compose logs vllm | tail -50

# 2. GPU ìƒíƒœ í™•ì¸
nvidia-smi

# 3. ì»¨í…Œì´ë„ˆ ì¬ì‹œì‘
docker compose restart vllm

# 4. ëª¨ë¸ ë¡œë”© ëŒ€ê¸° (5-10ë¶„)
timeout 600 bash -c 'until curl -f http://localhost:8000/v1/models; do sleep 15; done'
```

#### 2. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨

**ì¦ìƒ:**

- Gateway ì—ëŸ¬ ë¡œê·¸ì— DB ì—°ê²° ì˜¤ë¥˜
- ì‚¬ìš©ì ì¸ì¦ ì‹¤íŒ¨

**ëŒ€ì‘ ì ˆì°¨:**

```bash
# 1. PostgreSQL ìƒíƒœ í™•ì¸
docker compose exec postgres pg_isready

# 2. ì—°ê²° ìˆ˜ í™•ì¸
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "
SELECT count(*) FROM pg_stat_activity;"

# 3. í•„ìš”ì‹œ PostgreSQL ì¬ì‹œì‘
docker compose restart postgres

# 4. Gateway ì¬ì‹œì‘ (ì—°ê²° ì¬ì„¤ì •)
docker compose restart gateway
```

#### 3. ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±

**ì¦ìƒ:**

- ë¡œê·¸ì— "No space left on device"
- ìƒˆë¡œìš´ ëŒ€í™” ì €ì¥ ì‹¤íŒ¨

**ëŒ€ì‘ ì ˆì°¨:**

```bash
# 1. ìš©ëŸ‰ í™•ì¸
df -h

# 2. í° íŒŒì¼ë“¤ ì°¾ê¸°
du -sh * | sort -hr | head -10

# 3. ì„ì‹œ ì •ë¦¬
docker system prune -f
docker logs --details > /dev/null  # ë¡œê·¸ ë²„í¼ ë¹„ìš°ê¸°

# 4. ë¡œê·¸ íŒŒì¼ ì••ì¶•
find logs/ -name "*.log" -mtime +7 -exec gzip {} \;
```

### ì‘ê¸‰ ì—°ë½ì²˜ ë° ì—ìŠ¤ì»¬ë ˆì´ì…˜

```bash
# emergency_contacts.md
## ğŸš¨ ì‘ê¸‰ ì—°ë½ì²˜

### 1ì°¨ ëŒ€ì‘ (24ì‹œê°„)
- ìš´ì˜ ë‹´ë‹¹ì: [ì „í™”ë²ˆí˜¸]
- ê°œë°œ íŒ€ì¥: [ì „í™”ë²ˆí˜¸]

### 2ì°¨ ì—ìŠ¤ì»¬ë ˆì´ì…˜ (ì‹¬ê°í•œ ì¥ì• )
- CTO/ê¸°ìˆ ì±…ì„ì: [ì „í™”ë²ˆí˜¸]
- ì¸í”„ë¼ íŒ€: [ì „í™”ë²ˆí˜¸]

### ì™¸ë¶€ ì§€ì›
- í´ë¼ìš°ë“œ ì§€ì›íŒ€: [ì—°ë½ì²˜]
- NVIDIA ê¸°ìˆ ì§€ì›: [ì—°ë½ì²˜]

### ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ì±„ë„
- Slack: #vllm-operations
- ì´ë©”ì¼: ops@company.com
- ìƒí™©ì‹¤: [íšŒì˜ì‹¤/í™”ìƒíšŒì˜ ë§í¬]
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### GPU ì„±ëŠ¥ íŠœë‹

```bash
# gpu_tuning.sh
#!/bin/bash

# GPU í´ëŸ­ ìµœëŒ€í™” (NVIDIA GPU)
nvidia-smi -pm ENABLED
nvidia-smi -ac 877,1911  # ë©”ëª¨ë¦¬, GPU í´ëŸ­ ì„¤ì •

# GPU íŒŒì›Œ ë¦¬ë°‹ ì„¤ì •
nvidia-smi -pl 350  # 350Wë¡œ ì„¤ì • (GPU ëª¨ë¸ì— ë”°ë¼ ì¡°ì •)

# ì˜¨ë„ ëª¨ë‹ˆí„°ë§
nvidia-smi -q -d TEMPERATURE
```

### vLLM íŒŒë¼ë¯¸í„° ìµœì í™”

```bash
# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê¸°ë°˜ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°
#!/bin/bash

MODELS=("microsoft/DialoGPT-medium" "microsoft/DialoGPT-small")
UTILS=(0.4 0.5 0.6 0.7)
MAX_LENS=(2048 4096 8192)

for MODEL in "${MODELS[@]}"; do
    for UTIL in "${UTILS[@]}"; do
        for MAX_LEN in "${MAX_LENS[@]}"; do
            echo "Testing MODEL=$MODEL UTIL=$UTIL MAX_LEN=$MAX_LEN"

            # í™˜ê²½ë³€ìˆ˜ ì—…ë°ì´íŠ¸
            sed -i "s/MODEL_ID=.*/MODEL_ID=$MODEL/" .env.local
            sed -i "s/VLLM_UTIL=.*/VLLM_UTIL=$UTIL/" .env.local
            sed -i "s/VLLM_MAXLEN=.*/VLLM_MAXLEN=$MAX_LEN/" .env.local

            # ì„œë¹„ìŠ¤ ì¬ì‹œì‘
            docker compose restart vllm
            sleep 300  # ëª¨ë¸ ë¡œë”© ëŒ€ê¸°

            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            k6 run --duration 300s k6/load-test.js > "results_${MODEL##*/}_${UTIL}_${MAX_LEN}.txt"
        done
    done
done
```

### ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìµœì í™”

```sql
-- PostgreSQL ì„±ëŠ¥ íŠœë‹ ì¿¼ë¦¬
-- scripts/optimize_database.sql

-- 1. ì¸ë±ìŠ¤ ì‚¬ìš©ë¥  í™•ì¸
SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan DESC;

-- 2. ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ ìµœì í™”
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_messages_created_at_desc
ON messages (created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_request_logs_user_model
ON request_logs (user_id, model, created_at);

-- 3. í…Œì´ë¸” í†µê³„ ì—…ë°ì´íŠ¸
ANALYZE;

-- 4. ì˜¤ë˜ëœ ì„¸ì…˜ ì •ë¦¬
DELETE FROM user_sessions WHERE expires_at < NOW() - INTERVAL '7 days';
```

## ğŸ“ˆ ìš©ëŸ‰ ê³„íš

### ì„±ì¥ ì˜ˆì¸¡ ë° ë¦¬ì†ŒìŠ¤ ê³„íš

```bash
# capacity_planning.sh
#!/bin/bash

# í˜„ì¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
echo "=== í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ==="
echo "GPU ë©”ëª¨ë¦¬: $(nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader)"
echo "ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: $(free -h | grep Mem)"
echo "ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰: $(df -h /)"
echo "DB í¬ê¸°: $(docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "SELECT pg_size_pretty(pg_database_size('${POSTGRES_DB}'));")"

# ì›”ê°„ ì¦ê°€ìœ¨ ê³„ì‚°
echo "=== ì„±ì¥ ì¶”ì„¸ ë¶„ì„ ==="
docker compose exec postgres psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "
WITH monthly_stats AS (
    SELECT
        DATE_TRUNC('month', created_at) as month,
        COUNT(*) as requests,
        COUNT(DISTINCT user_id) as active_users
    FROM request_logs
    WHERE created_at >= NOW() - INTERVAL '6 months'
    GROUP BY DATE_TRUNC('month', created_at)
    ORDER BY month
)
SELECT
    month,
    requests,
    active_users,
    LAG(requests) OVER (ORDER BY month) as prev_requests,
    ROUND((requests - LAG(requests) OVER (ORDER BY month)) * 100.0 / LAG(requests) OVER (ORDER BY month), 2) as growth_rate
FROM monthly_stats;"
```

### í™•ì¥ ê³„íš

```yaml
# docker-compose.scale.yml
# ë†’ì€ ë¶€í•˜ë¥¼ ìœ„í•œ í™•ì¥ ì„¤ì •

version: '3.9'
services:
  gateway:
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '1.0'
          memory: 2G

  nginx:
    volumes:
      - ./nginx/nginx.scale.conf:/etc/nginx/nginx.conf

  postgres:
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
    environment:
      - shared_preload_libraries=pg_stat_statements
      - max_connections=200
      - work_mem=16MB
```

ì´ì œ vLLM ì±—ë´‡ ì„œë¹„ìŠ¤ì˜ ì™„ì „í•œ ìš´ì˜ ì²´ê³„ê°€ ê°–ì¶°ì¡ŒìŠµë‹ˆë‹¤! ì¼ì¼ ì ê²€ë¶€í„° ì¥ì•  ëŒ€ì‘, ì„±ëŠ¥ ìµœì í™”ê¹Œì§€ ëª¨ë“  ìš´ì˜ ìƒí™©ì— ëŒ€ë¹„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸš€
