# ğŸ§ª vLLM ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ì „ëµê³¼ ì‹¤í–‰ ë°©ë²•ì„ ë‹¤ë£¨ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ¯ í…ŒìŠ¤íŠ¸ ì „ëµ

### **í…ŒìŠ¤íŠ¸ í”¼ë¼ë¯¸ë“œ**
```
        ğŸ”º E2E Tests (5%)
       /   ì „ì²´ ì‹œìŠ¤í…œ í†µí•©
      /
     ğŸ”º Integration Tests (15%)  
    /   API + Database + vLLM
   /
  ğŸ”º Unit Tests (80%)
 /   ê°œë³„ í•¨ìˆ˜/ì»´í¬ë„ŒíŠ¸
```

### **í…ŒìŠ¤íŠ¸ ë¶„ë¥˜**

1. **Unit Tests** - ê°œë³„ í•¨ìˆ˜/í´ë˜ìŠ¤/ì»´í¬ë„ŒíŠ¸
2. **Integration Tests** - ëª¨ë“ˆ ê°„ ì—°ë™
3. **API Tests** - REST API ì—”ë“œí¬ì¸íŠ¸  
4. **Performance Tests** - ë¶€í•˜/ì„±ëŠ¥
5. **E2E Tests** - ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤

---

## ğŸ”§ Backend í…ŒìŠ¤íŠ¸ (Gateway)

### **í™˜ê²½ ì„¤ì •**

```bash
cd gateway

# í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
pip install pytest pytest-asyncio httpx pytest-cov

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
export TEST_DATABASE_URL="postgresql+asyncpg://test:test@localhost:5433/test_chatdb"
```

### **Unit Tests**

```python
# tests/unit/test_model_manager.py
import pytest
from unittest.mock import AsyncMock, patch, MagicMock

from app.services.model_manager import VLLMModelManager
from app.schemas.model import ModelProfile

@pytest.fixture
def model_manager():
    return VLLMModelManager()

@pytest.fixture  
def sample_profile():
    return ModelProfile(
        name="Test Model",
        model_id="test/model",
        description="Test model for unit tests",
        max_model_len=2048,
        tensor_parallel_size=1,
        gpu_memory_utilization=0.8,
        dtype="float16",
        swap_space=2,
        hardware_requirements={
            "min_vram_gb": 8,
            "recommended_vram_gb": 16
        }
    )

@pytest.mark.asyncio
async def test_get_hardware_info(model_manager):
    """GPU í•˜ë“œì›¨ì–´ ì •ë³´ ì¡°íšŒ í…ŒìŠ¤íŠ¸"""
    with patch('subprocess.run') as mock_run:
        # nvidia-smi ëª…ë ¹ì–´ ê²°ê³¼ ëª¨í‚¹
        mock_run.return_value.stdout = """
0, GeForce RTX 3090, 24576, 2048, 93
1, GeForce RTX 3090, 24576, 1024, 45
        """.strip()
        mock_run.return_value.returncode = 0
        
        hardware_info = await model_manager._get_hardware_info()
        
        assert hardware_info["gpu_count"] == 2
        assert hardware_info["total_vram_gb"] == 48.0
        assert len(hardware_info["gpus"]) == 2
        assert hardware_info["gpus"][0]["name"] == "GeForce RTX 3090"

def test_check_hardware_compatibility(model_manager, sample_profile):
    """í•˜ë“œì›¨ì–´ í˜¸í™˜ì„± ê²€ì¦ í…ŒìŠ¤íŠ¸"""
    hardware_info = {
        "gpu_count": 2,
        "total_vram_gb": 48.0,
        "available_vram_gb": 45.0
    }
    
    compatibility = model_manager._check_hardware_compatibility(sample_profile, hardware_info)
    
    assert compatibility["compatible"] is True
    assert "sufficient_vram" in compatibility
    assert "sufficient_gpus" in compatibility

@pytest.mark.asyncio
async def test_model_switch_success(model_manager):
    """ëª¨ë¸ ì „í™˜ ì„±ê³µ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    with patch.object(model_manager, '_get_hardware_info') as mock_hardware, \
         patch.object(model_manager, '_restart_vllm_container') as mock_restart, \
         patch.object(model_manager, '_wait_for_model_ready') as mock_wait:
        
        mock_hardware.return_value = {"gpu_count": 2, "available_vram_gb": 45.0}
        mock_restart.return_value = True
        mock_wait.return_value = True
        
        # í…ŒìŠ¤íŠ¸ìš© í”„ë¡œíŒŒì¼ ì¶”ê°€
        model_manager.profiles["test-model"] = sample_profile
        
        result = await model_manager.switch_model("test-model")
        
        assert result is True
        assert model_manager.current_profile == "test-model"
        assert model_manager.status == "running"

@pytest.mark.asyncio
async def test_model_switch_incompatible_hardware(model_manager, sample_profile):
    """í•˜ë“œì›¨ì–´ ë¹„í˜¸í™˜ ì‹œ ëª¨ë¸ ì „í™˜ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸"""
    with patch.object(model_manager, '_get_hardware_info') as mock_hardware:
        mock_hardware.return_value = {"gpu_count": 1, "available_vram_gb": 4.0}
        
        model_manager.profiles["test-model"] = sample_profile
        
        result = await model_manager.switch_model("test-model")
        
        assert result is False
        assert model_manager.status == "error"
```

### **Integration Tests**

```python
# tests/integration/test_models_api.py
import pytest
from fastapi.testclient import TestClient
import asyncio

from app.main import app
from app.services.model_manager import model_manager

client = TestClient(app)

@pytest.fixture(autouse=True)
async def reset_model_manager():
    """ê° í…ŒìŠ¤íŠ¸ ì „ì— ëª¨ë¸ ë§¤ë‹ˆì € ìƒíƒœ ì´ˆê¸°í™”"""
    model_manager.current_profile = None
    model_manager.status = "stopped"
    yield
    # í…ŒìŠ¤íŠ¸ í›„ ì •ë¦¬ ì‘ì—…

def test_get_model_status():
    """ëª¨ë¸ ìƒíƒœ API í…ŒìŠ¤íŠ¸"""
    response = client.get("/api/models/status")
    assert response.status_code == 200
    
    data = response.json()
    assert "current_profile" in data
    assert "status" in data
    assert "available_profiles" in data
    assert "hardware_info" in data

def test_get_model_profiles():
    """ëª¨ë¸ í”„ë¡œíŒŒì¼ ëª©ë¡ API í…ŒìŠ¤íŠ¸"""
    response = client.get("/api/models/profiles")
    assert response.status_code == 200
    
    data = response.json()
    assert "profiles" in data
    assert "current_profile" in data
    assert isinstance(data["profiles"], dict)
    assert len(data["profiles"]) > 0

def test_model_switch_nonexistent_profile():
    """ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì „í™˜ ì‹œ ì˜¤ë¥˜ ì²˜ë¦¬"""
    response = client.post(
        "/api/models/switch",
        json={"profile_id": "nonexistent-model"}
    )
    assert response.status_code == 404

def test_get_hardware_recommendations():
    """í•˜ë“œì›¨ì–´ ì¶”ì²œ API í…ŒìŠ¤íŠ¸"""
    response = client.get("/api/models/hardware-recommendations")
    assert response.status_code == 200
    
    data = response.json()
    assert "current_hardware" in data
    assert "recommended_profiles" in data
    assert "compatible_profiles" in data
    assert "incompatible_profiles" in data

def test_reload_profiles():
    """í”„ë¡œíŒŒì¼ ì¬ë¡œë“œ API í…ŒìŠ¤íŠ¸"""
    response = client.post("/api/models/reload")
    assert response.status_code == 200
    
    data = response.json()
    assert data["success"] is True
    assert "profiles" in data
```

### **API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**

```python
# tests/performance/test_api_performance.py
import pytest
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor
import requests

BASE_URL = "http://localhost:8080"

def test_model_status_response_time():
    """ëª¨ë¸ ìƒíƒœ API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸"""
    start_time = time.time()
    response = requests.get(f"{BASE_URL}/api/models/status")
    end_time = time.time()
    
    assert response.status_code == 200
    assert (end_time - start_time) < 1.0  # 1ì´ˆ ì´ë‚´ ì‘ë‹µ

def test_concurrent_api_calls():
    """ë™ì‹œ API í˜¸ì¶œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    def make_request():
        return requests.get(f"{BASE_URL}/api/models/status")
    
    with ThreadPoolExecutor(max_workers=10) as executor:
        start_time = time.time()
        futures = [executor.submit(make_request) for _ in range(50)]
        responses = [future.result() for future in futures]
        end_time = time.time()
    
    # ëª¨ë“  ìš”ì²­ì´ ì„±ê³µí•´ì•¼ í•¨
    for response in responses:
        assert response.status_code == 200
    
    # 50ê°œ ìš”ì²­ì´ 5ì´ˆ ì´ë‚´ì— ì™„ë£Œë˜ì–´ì•¼ í•¨
    assert (end_time - start_time) < 5.0
    
    # í‰ê·  ì‘ë‹µ ì‹œê°„ í™•ì¸
    avg_time = (end_time - start_time) / len(responses)
    assert avg_time < 0.1  # í‰ê·  100ms ì´ë‚´

def test_chat_api_performance():
    """ì±„íŒ… API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ìŠ¤íŠ¸ë¦¬ë° ì œì™¸)"""
    payload = {
        "messages": [{"role": "user", "content": "Hello"}],
        "model": "current",
        "stream": False
    }
    
    start_time = time.time()
    response = requests.post(
        f"{BASE_URL}/api/chat",
        json=payload,
        headers={"Authorization": "Bearer test-token"}
    )
    end_time = time.time()
    
    assert response.status_code == 200
    response_time = end_time - start_time
    
    # TTFT (Time to First Token) ëª©í‘œ: 2ì´ˆ ì´ë‚´
    assert response_time < 2.0
```

---

## ğŸ¨ Frontend í…ŒìŠ¤íŠ¸

### **í™˜ê²½ ì„¤ì •**

```bash
cd frontend

# í…ŒìŠ¤íŠ¸ ì˜ì¡´ì„± ì„¤ì¹˜
npm install --save-dev @testing-library/react @testing-library/jest-dom @testing-library/user-event vitest jsdom

# Vitest ì„¤ì • ì¶”ê°€ (vite.config.ts)
```

### **ì»´í¬ë„ŒíŠ¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**

```typescript
// src/components/chat/__tests__/ModelSelector.test.tsx
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import { ModelSelector } from '../ModelSelector';

const mockModels = {
  "deepseek-r1-distill-qwen-14b": {
    name: "DeepSeek R1 Distill Qwen 14B",
    description: "ìµœì‹  DeepSeek R1 distilled ëª¨ë¸"
  },
  "phi3-mini": {
    name: "Phi-3 Mini 3.8B",
    description: "Microsoft ê²½ëŸ‰ ëª¨ë¸"
  }
};

const mockOnModelChange = jest.fn();

describe('ModelSelector', () => {
  beforeEach(() => {
    mockOnModelChange.mockClear();
  });

  test('ëª¨ë¸ ëª©ë¡ì´ ì˜¬ë°”ë¥´ê²Œ ë Œë”ë§ëœë‹¤', () => {
    render(
      <ModelSelector
        models={mockModels}
        currentModel="deepseek-r1-distill-qwen-14b"
        onModelChange={mockOnModelChange}
        isLoading={false}
      />
    );

    expect(screen.getByText('DeepSeek R1 Distill Qwen 14B')).toBeInTheDocument();
    expect(screen.getByText('Phi-3 Mini 3.8B')).toBeInTheDocument();
  });

  test('ëª¨ë¸ ì„ íƒ ì‹œ ì½œë°±ì´ í˜¸ì¶œëœë‹¤', async () => {
    const user = userEvent.setup();
    
    render(
      <ModelSelector
        models={mockModels}
        currentModel="deepseek-r1-distill-qwen-14b"
        onModelChange={mockOnModelChange}
        isLoading={false}
      />
    );

    const selectButton = screen.getByRole('button');
    await user.click(selectButton);

    const phi3Option = screen.getByText('Phi-3 Mini 3.8B');
    await user.click(phi3Option);

    expect(mockOnModelChange).toHaveBeenCalledWith('phi3-mini');
  });

  test('ë¡œë”© ìƒíƒœì—ì„œ ë¹„í™œì„±í™”ëœë‹¤', () => {
    render(
      <ModelSelector
        models={mockModels}
        currentModel="deepseek-r1-distill-qwen-14b"
        onModelChange={mockOnModelChange}
        isLoading={true}
      />
    );

    const selectButton = screen.getByRole('button');
    expect(selectButton).toBeDisabled();
    expect(screen.getByText('ì „í™˜ ì¤‘...')).toBeInTheDocument();
  });
});
```

### **í†µí•© í…ŒìŠ¤íŠ¸**

```typescript
// src/hooks/__tests__/useModelManagement.test.ts
import { renderHook, act } from '@testing-library/react';
import { useModelManagement } from '../useModelManagement';

// API ëª¨í‚¹
const mockFetch = jest.fn();
global.fetch = mockFetch;

describe('useModelManagement', () => {
  beforeEach(() => {
    mockFetch.mockClear();
  });

  test('ëª¨ë¸ ìƒíƒœë¥¼ ì˜¬ë°”ë¥´ê²Œ ê°€ì ¸ì˜¨ë‹¤', async () => {
    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        current_profile: 'deepseek-r1-distill-qwen-14b',
        status: 'running',
        available_profiles: mockModels
      })
    });

    const { result } = renderHook(() => useModelManagement());

    await act(async () => {
      await result.current.fetchModelStatus();
    });

    expect(result.current.currentModel).toBe('deepseek-r1-distill-qwen-14b');
    expect(result.current.status).toBe('running');
  });

  test('ëª¨ë¸ ì „í™˜ì´ ì˜¬ë°”ë¥´ê²Œ ë™ì‘í•œë‹¤', async () => {
    mockFetch.mockResolvedValueOnce({
      ok: true,
      json: () => Promise.resolve({
        success: true,
        message: 'ëª¨ë¸ ì „í™˜ì„ ì‹œì‘í•©ë‹ˆë‹¤'
      })
    });

    const { result } = renderHook(() => useModelManagement());

    await act(async () => {
      await result.current.switchModel('phi3-mini');
    });

    expect(mockFetch).toHaveBeenCalledWith(
      'http://localhost:8080/api/models/switch',
      expect.objectContaining({
        method: 'POST',
        body: JSON.stringify({ profile_id: 'phi3-mini' })
      })
    );
  });
});
```

---

## ğŸš€ E2E í…ŒìŠ¤íŠ¸ (Playwright)

### **í™˜ê²½ ì„¤ì •**

```bash
# Playwright ì„¤ì¹˜
npm init playwright@latest

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
npx playwright test
```

### **ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸**

```typescript
// tests/e2e/model-management.spec.ts
import { test, expect } from '@playwright/test';

test.describe('ëª¨ë¸ ê´€ë¦¬ E2E í…ŒìŠ¤íŠ¸', () => {
  test.beforeEach(async ({ page }) => {
    await page.goto('http://localhost:3000');
  });

  test('ëª¨ë¸ ì„ íƒ ë° ì „í™˜ ì „ì²´ í”Œë¡œìš°', async ({ page }) => {
    // 1. í˜„ì¬ ëª¨ë¸ ìƒíƒœ í™•ì¸
    await expect(page.locator('[data-testid="current-model"]')).toBeVisible();
    
    // 2. ëª¨ë¸ ì„ íƒ ë“œë¡­ë‹¤ìš´ ì—´ê¸°
    await page.click('[data-testid="model-selector"]');
    
    // 3. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ í™•ì¸
    await expect(page.locator('[data-testid="model-option"]')).toHaveCount(10);
    
    // 4. ë‹¤ë¥¸ ëª¨ë¸ ì„ íƒ
    await page.click('[data-testid="model-option-phi3-mini"]');
    
    // 5. ì „í™˜ ì¤‘ ìƒíƒœ í™•ì¸
    await expect(page.locator('text=ì „í™˜ ì¤‘')).toBeVisible();
    
    // 6. ì „í™˜ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 3ë¶„)
    await expect(page.locator('text=ì „í™˜ ì™„ë£Œ')).toBeVisible({ timeout: 180000 });
    
    // 7. ìƒˆ ëª¨ë¸ë¡œ ì±„íŒ… í…ŒìŠ¤íŠ¸
    await page.fill('[data-testid="chat-input"]', 'ì•ˆë…•í•˜ì„¸ìš”!');
    await page.click('[data-testid="send-button"]');
    
    // 8. AI ì‘ë‹µ í™•ì¸
    await expect(page.locator('[data-testid="ai-message"]').first()).toBeVisible({ timeout: 10000 });
  });

  test('í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ ì„ íƒ ì‹œ ê²½ê³  í‘œì‹œ', async ({ page }) => {
    // GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•œ ìƒí™©ì„ ì‹œë®¬ë ˆì´ì…˜
    await page.route('**/api/models/hardware-recommendations', async route => {
      await route.fulfill({
        json: {
          current_hardware: { available_vram_gb: 8 },
          compatible_profiles: ['phi3-mini'],
          incompatible_profiles: ['llama3-70b-instruct']
        }
      });
    });

    await page.reload();
    await page.click('[data-testid="model-selector"]');
    
    // í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì€ ë¹„í™œì„±í™”ë˜ì–´ì•¼ í•¨
    await expect(page.locator('[data-testid="model-option-llama3-70b-instruct"]')).toHaveClass(/disabled/);
    
    // ê²½ê³  ë©”ì‹œì§€ í™•ì¸
    await page.hover('[data-testid="model-option-llama3-70b-instruct"]');
    await expect(page.locator('text=í˜„ì¬ í•˜ë“œì›¨ì–´ë¡œ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤')).toBeVisible();
  });
});
```

---

## ğŸ“Š í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ë¦¬í¬íŒ…

### **í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ëª…ë ¹ì–´**

```bash
# Backend í…ŒìŠ¤íŠ¸
cd gateway
pytest tests/ -v --cov=app --cov-report=html

# Frontend í…ŒìŠ¤íŠ¸  
cd frontend
npm run test

# E2E í…ŒìŠ¤íŠ¸
npx playwright test

# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
cd k6
k6 run load-test.js
```

### **CI/CD íŒŒì´í”„ë¼ì¸ í†µí•©**

```yaml
# .github/workflows/test.yml
name: Test Suite

on: [push, pull_request]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:16
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_chatdb
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        cd gateway
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov
    
    - name: Run tests
      run: |
        cd gateway
        pytest tests/ -v --cov=app --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./gateway/coverage.xml

  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install dependencies
      run: |
        cd frontend
        npm install
    
    - name: Run tests
      run: |
        cd frontend
        npm run test:coverage

  e2e-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    - uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install Playwright
      run: |
        cd frontend
        npx playwright install
    
    - name: Start services
      run: |
        docker compose -f docker-compose.yml -f docker-compose.test.yml up -d
        sleep 30  # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
    
    - name: Run E2E tests
      run: |
        cd frontend  
        npx playwright test
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: playwright-report
        path: frontend/playwright-report/
```

### **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ**

- **Backend**: 80% ì´ìƒ
- **Frontend**: 70% ì´ìƒ  
- **E2E**: ì£¼ìš” ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ 100% ì»¤ë²„
- **Performance**: ì‘ë‹µì‹œê°„ SLA 100% ë‹¬ì„±

---

## ğŸ” í…ŒìŠ¤íŠ¸ ëª¨ë²” ì‚¬ë¡€

### **ì¢‹ì€ í…ŒìŠ¤íŠ¸ ì‘ì„±ë²•**

1. **AAA íŒ¨í„´**: Arrange, Act, Assert
2. **ë…ë¦½ì„±**: ê° í…ŒìŠ¤íŠ¸ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥
3. **ì¬í˜„ì„±**: í•­ìƒ ê°™ì€ ê²°ê³¼ ë³´ì¥
4. **ê°€ë…ì„±**: í…ŒìŠ¤íŠ¸ ì´ë¦„ê³¼ ë‚´ìš©ì´ ëª…í™•
5. **ë¹ ë¥¸ ì‹¤í–‰**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ëŠ” ë¹ ë¥´ê²Œ

### **í…ŒìŠ¤íŠ¸ ë°ì´í„° ê´€ë¦¬**

```python
# tests/fixtures/model_fixtures.py
@pytest.fixture
def sample_model_profiles():
    return {
        "test-small": {
            "name": "Test Small Model",
            "model_id": "microsoft/DialoGPT-small",
            "hardware_requirements": {"min_vram_gb": 2}
        },
        "test-large": {
            "name": "Test Large Model", 
            "model_id": "test/large-model",
            "hardware_requirements": {"min_vram_gb": 32}
        }
    }
```

### **Mock ì „ëµ**

```python
# ì™¸ë¶€ ì˜ì¡´ì„±ì€ í•­ìƒ mock
@patch('subprocess.run')  # nvidia-smi í˜¸ì¶œ
@patch('docker.from_env')  # Docker API í˜¸ì¶œ
@patch('httpx.AsyncClient.post')  # HTTP ìš”ì²­
```

---

## âœ… í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸

### **ê°œë°œ ì¤‘**
- [ ] ìƒˆ ê¸°ëŠ¥ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] ê¸°ì¡´ í…ŒìŠ¤íŠ¸ê°€ í†µê³¼í•˜ëŠ”ì§€ í™•ì¸
- [ ] í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ í™•ì¸

### **PR ì œì¶œ ì „**
- [ ] ì „ì²´ í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ì‹¤í–‰
- [ ] E2E í…ŒìŠ¤íŠ¸ í†µê³¼ í™•ì¸
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í™•ì¸
- [ ] ì½”ë“œ ì»¤ë²„ë¦¬ì§€ ëª©í‘œ ë‹¬ì„±

### **ë°°í¬ ì „**
- [ ] í”„ë¡œë•ì…˜ ìœ ì‚¬ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
- [ ] ë¶€í•˜ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë¡¤ë°± ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸

---

## ğŸ“ˆ ì§€ì†ì  ê°œì„ 

### **í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­ ì¶”ì **
- í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì‹œê°„
- ì»¤ë²„ë¦¬ì§€ ë³€í™” ì¶”ì´
- í”Œë ˆì´í‚¤ í…ŒìŠ¤íŠ¸ ì‹ë³„
- ë²„ê·¸ ë°œê²¬ìœ¨

### **ì •ê¸° ë¦¬ë·°**
- ì›”ê°„ í…ŒìŠ¤íŠ¸ ì „ëµ ë¦¬ë·°
- ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ë„êµ¬ ë„ì… ê²€í† 
- íŒ€ í”¼ë“œë°± ìˆ˜ì§‘ ë° ë°˜ì˜

ì´ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œë¥¼ í†µí•´ ë†’ì€ í’ˆì§ˆì˜ ì•ˆì •ì ì¸ vLLM ì„œë¹„ìŠ¤ë¥¼ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
